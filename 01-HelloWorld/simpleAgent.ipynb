{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Agent\n",
    "\n",
    "使用 langchain 可以很方便地构造一个 Agent。不过在创建 Agent 之前，首先得知道 Agent 使用什么 Tools。\n",
    "\n",
    "这个测试之中，Agent 将使用一个本地 RAG 和 一个网络搜索服务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. LLM 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    openai_api_key=\"not-needed\"\n",
    ")\n",
    "\n",
    "\n",
    "# 配置Embedding模型\n",
    "modelPath = \"BAAI/bge-base-en-v1.5\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "# model_kwargs = {'device':'cpu'}\n",
    "model_kwargs = {'device':'cuda'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")\n",
    "\n",
    "\n",
    "# 向量化数据\n",
    "# 1. 加载数据\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/get_started/introduction\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. 向量化处理\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定义 Agent 工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langchain_search\",\n",
    "    \"Search for information about Langchain. For any questions about Langchain, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 Agent 工具列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()\n",
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 langchain 中，[langchainHub](https://smith.langchain.com/hub) 是官方分享prompt的社区。可以通过 langchainhub 库进行拉去，方便引入到项目之中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchainhub in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (0.1.14)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (from langchainhub) (2.31.0)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (from langchainhub) (2.31.0.20240125)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\applications\\miniconda3\\envs\\llamaindex-learning\\lib\\site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# 拉去社区prompt\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# 定义agent\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "#\"\"\"Whether or not run in verbose mode. In verbose mode, some intermediate logs\n",
    "#    will be printed to the console. Defaults to the global `verbose` value,\n",
    "#    accessible via `langchain.globals.get_verbose()`.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过agent解决问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangChain is an AI language model designed to assist with various text-based tasks. While it may not be able to directly build an LLM (Master of Laws) application for you, it can certainly provide valuable support in several ways:\n",
      "\n",
      "1. Drafting statements of purpose: LangChain can help you craft a compelling statement of purpose by suggesting phrases, structures, and arguments based on your input. It can also help ensure that the language is clear, concise, and professional.\n",
      "2. Editing personal statements: LangChain can review your draft statements of purpose and suggest improvements in grammar, style, and coherence. It can also provide feedback on content to help you strengthen your application.\n",
      "3. Preparing for interviews: LangChain can help you prepare for LLM interviews by providing sample questions and suggested responses based on common topics. It can also help you practice answering questions effectively and confidently.\n",
      "4. Researching law schools and programs: LangChain can help you research various LLM programs and law schools by providing information on their curricula, faculty, location, tuition, and student demographics. It can also help you compare different programs to find the best fit for your goals and interests.\n",
      "5. Writing essays and other application components: LangChain can help you write other application components such as essays, letters of recommendation, and CVs/resumes. It can suggest structures, arguments, and phrases that are appropriate for each component and help ensure that they are well-written and professional.\n",
      "\n",
      "Overall, LangChain can be a valuable tool in helping you build a strong LLM application by providing assistance with drafting, editing, researching, and writing various components of the application. However, it is important to remember that the final product should still reflect your unique voice, experiences, and qualifications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langchain help with building LLM Application?',\n",
       " 'output': 'LangChain is an AI language model designed to assist with various text-based tasks. While it may not be able to directly build an LLM (Master of Laws) application for you, it can certainly provide valuable support in several ways:\\n\\n1. Drafting statements of purpose: LangChain can help you craft a compelling statement of purpose by suggesting phrases, structures, and arguments based on your input. It can also help ensure that the language is clear, concise, and professional.\\n2. Editing personal statements: LangChain can review your draft statements of purpose and suggest improvements in grammar, style, and coherence. It can also provide feedback on content to help you strengthen your application.\\n3. Preparing for interviews: LangChain can help you prepare for LLM interviews by providing sample questions and suggested responses based on common topics. It can also help you practice answering questions effectively and confidently.\\n4. Researching law schools and programs: LangChain can help you research various LLM programs and law schools by providing information on their curricula, faculty, location, tuition, and student demographics. It can also help you compare different programs to find the best fit for your goals and interests.\\n5. Writing essays and other application components: LangChain can help you write other application components such as essays, letters of recommendation, and CVs/resumes. It can suggest structures, arguments, and phrases that are appropriate for each component and help ensure that they are well-written and professional.\\n\\nOverall, LangChain can be a valuable tool in helping you build a strong LLM application by providing assistance with drafting, editing, researching, and writing various components of the application. However, it is important to remember that the final product should still reflect your unique voice, experiences, and qualifications.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langchain help with building LLM Application?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
