{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Retrieval Chain\n",
    "\n",
    "ä½¿ç”¨ langchain å®ç°ä¸€ä¸ªç®€å•çš„ Retrieval ChatBot\n",
    "å‚è€ƒï¼š[conversation-retrieval-chain](https://python.langchain.com/docs/get_started/quickstart#conversation-retrieval-chain)\n",
    "\n",
    "åœ¨èŠå¤©åº”ç”¨ä¹‹ä¸­ï¼Œéœ€è¦è®© LLM çŸ¥é“èŠå¤©ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œä»è€Œæ‰èƒ½ä½œå‡ºç¬¦åˆè¯­å¢ƒçš„å›ç­”ã€‚\n",
    "\n",
    "æˆ‘ä»¬åœ¨ simpleLLM.ipynb åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ï¼Œè®© LLM èƒ½å¤Ÿè·å–æ•´ä¸ªèŠå¤©å†å²ä¿¡æ¯è®°å½•ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    openai_api_key=\"not-needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "modelPath = \"BAAI/bge-base-en-v1.5\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "# model_kwargs = {'device':'cpu'}\n",
    "model_kwargs = {'device':'cuda'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# åŠ è½½æ•°æ®\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/get_started/introduction\")\n",
    "docs = loader.load()\n",
    "\n",
    "# å‘é‡åŒ–å¤„ç†\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®© LLM èƒ½å¤Ÿè·å–æ•´ä¸ª chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# æ„é€ promptæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ„é€ ä¸Šä¸‹æ–‡è¿›è¡Œæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Introduction | ğŸ¦œï¸ğŸ”— Langchain', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ğŸ¦œï¸ğŸ”— Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'}),\n",
       " Document(page_content=\"Skip to main contentğŸ¦œï¸ğŸ”— LangChainDocsUse casesIntegrationsGuidesAPIMoreVersioningChangelogDeveloper's guideTemplatesCookbooksTutorialsYouTubeğŸ¦œï¸ğŸ”—LangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS DocsChatSearchGet startedIntroductionInstallationQuickstartSecurityLangChain Expression LanguageGet startedWhy use LCELInterfaceStreamingHow toCookbookLangChain Expression Language (LCEL)ModulesModel I/ORetrievalAgentsChainsMoreLangServeLangSmithLangGraphGet startedIntroductionOn this pageIntroductionLangChain is a framework for developing applications powered by language models. It enables applications that:Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)This framework consists of several parts.LangChain Libraries: The Python and JavaScript libraries. Contains interfaces and integrations for a myriad of components, a basic run time for combining these components into chains and agents, and off-the-shelf implementations of chains and agents.LangChain Templates: A collection of easily deployable reference architectures for a wide variety of tasks.LangServe: A library for deploying LangChain chains as a REST API.LangSmith: A developer platform that lets you debug, test, evaluate, and monitor chains built on any LLM framework and seamlessly integrates with LangChain.Together, these products simplify the entire application lifecycle:Develop: Write your applications in LangChain/LangChain.js. Hit the ground running using Templates for reference.Productionize: Use LangSmith to inspect, test and monitor your chains, so that you can constantly improve and deploy with confidence.Deploy: Turn any chain into an API with LangServe.LangChain Libraries\\u200bThe main value props of the LangChain packages are:Components: composable tools and integrations for working with language models. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or notOff-the-shelf chains: built-in assemblages of components for accomplishing higher-level tasksOff-the-shelf chains make it easy to get started. Components make it easy to customize existing chains and build new ones.The LangChain libraries themselves are made up of several different packages.langchain-core: Base abstractions and LangChain Expression Language.langchain-community: Third party integrations.langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.Get started\\u200bHereâ€™s how to install LangChain, set up your environment, and start building.We recommend following our Quickstart guide to familiarize yourself with the framework by building your first LangChain application.Read up on our Security best practices to make sure you're developing safely with LangChain.noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.LangChain Expression Language (LCEL)\\u200bLCEL is a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest â€œprompt + LLMâ€ chain to the most complex chains.Overview: LCEL and its benefitsInterface: The standard interface for LCEL objectsHow-to: Key features of LCELCookbook: Example code for accomplishing common tasksModules\\u200bLangChain provides standard, extendable interfaces and integrations for the following modules:Model I/O\\u200bInterface with language modelsRetrieval\\u200bInterface with application-specific dataAgents\\u200bLet models choose which tools to use given high-level directivesExamples, ecosystem, and resources\\u200bUse cases\\u200bWalkthroughs and techniques for common end-to-end use cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Integrations\\u200bLangChain is part of a rich ecosystem of tools that\", metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ğŸ¦œï¸ğŸ”— Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'}),\n",
       " Document(page_content=\"and techniques for common end-to-end use cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Integrations\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations.Guides\\u200bBest practices for developing with LangChain.API reference\\u200bHead to the reference section for full documentation of all classes and methods in the LangChain and LangChain Experimental Python packages.Developer's guide\\u200bCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.PreviousGet startedNextInstallationLangChain LibrariesGet startedLangChain Expression Language (LCEL)ModulesExamples, ecosystem, and resourcesUse casesIntegrationsGuidesAPI referenceDeveloper's guideCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogYouTubeCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ğŸ¦œï¸ğŸ”— Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can langchain help build my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å†åšä¸€ä¸ªæµ‹è¯•ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# å¤„ç†æµæ°´çº¿\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can Langchain help build my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content=\"Skip to main contentğŸ¦œï¸ğŸ”— LangChainDocsUse casesIntegrationsGuidesAPIMoreVersioningChangelogDeveloper's guideTemplatesCookbooksTutorialsYouTubeğŸ¦œï¸ğŸ”—LangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS DocsChatSearchGet startedIntroductionInstallationQuickstartSecurityLangChain Expression LanguageGet startedWhy use LCELInterfaceStreamingHow toCookbookLangChain Expression Language (LCEL)ModulesModel I/ORetrievalAgentsChainsMoreLangServeLangSmithLangGraphGet startedIntroductionOn this pageIntroductionLangChain is a framework for developing applications powered by language models. It enables applications that:Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)This framework consists of several parts.LangChain Libraries: The Python and JavaScript libraries. Contains interfaces and integrations for a myriad of components, a basic run time for combining these components into chains and agents, and off-the-shelf implementations of chains and agents.LangChain Templates: A collection of easily deployable reference architectures for a wide variety of tasks.LangServe: A library for deploying LangChain chains as a REST API.LangSmith: A developer platform that lets you debug, test, evaluate, and monitor chains built on any LLM framework and seamlessly integrates with LangChain.Together, these products simplify the entire application lifecycle:Develop: Write your applications in LangChain/LangChain.js. Hit the ground running using Templates for reference.Productionize: Use LangSmith to inspect, test and monitor your chains, so that you can constantly improve and deploy with confidence.Deploy: Turn any chain into an API with LangServe.LangChain Libraries\\u200bThe main value props of the LangChain packages are:Components: composable tools and integrations for working with language models. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or notOff-the-shelf chains: built-in assemblages of components for accomplishing higher-level tasksOff-the-shelf chains make it easy to get started. Components make it easy to customize existing chains and build new ones.The LangChain libraries themselves are made up of several different packages.langchain-core: Base abstractions and LangChain Expression Language.langchain-community: Third party integrations.langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.Get started\\u200bHereâ€™s how to install LangChain, set up your environment, and start building.We recommend following our Quickstart guide to familiarize yourself with the framework by building your first LangChain application.Read up on our Security best practices to make sure you're developing safely with LangChain.noteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.LangChain Expression Language (LCEL)\\u200bLCEL is a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest â€œprompt + LLMâ€ chain to the most complex chains.Overview: LCEL and its benefitsInterface: The standard interface for LCEL objectsHow-to: Key features of LCELCookbook: Example code for accomplishing common tasksModules\\u200bLangChain provides standard, extendable interfaces and integrations for the following modules:Model I/O\\u200bInterface with language modelsRetrieval\\u200bInterface with application-specific dataAgents\\u200bLet models choose which tools to use given high-level directivesExamples, ecosystem, and resources\\u200bUse cases\\u200bWalkthroughs and techniques for common end-to-end use cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Integrations\\u200bLangChain is part of a rich ecosystem of tools that\", metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ğŸ¦œï¸ğŸ”— Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'}),\n",
       "  Document(page_content='Introduction | ğŸ¦œï¸ğŸ”— Langchain', metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ğŸ¦œï¸ğŸ”— Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'}),\n",
       "  Document(page_content=\"and techniques for common end-to-end use cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Integrations\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations.Guides\\u200bBest practices for developing with LangChain.API reference\\u200bHead to the reference section for full documentation of all classes and methods in the LangChain and LangChain Experimental Python packages.Developer's guide\\u200bCheck out the developer's guide for guidelines on contributing and help getting your dev environment set up.PreviousGet startedNextInstallationLangChain LibrariesGet startedLangChain Expression Language (LCEL)ModulesExamples, ecosystem, and resourcesUse casesIntegrationsGuidesAPI referenceDeveloper's guideCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogYouTubeCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ğŸ¦œï¸ğŸ”— Langchain', 'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en'})],\n",
       " 'answer': 'LangChain is a framework for developing applications powered by language models. It provides components, integrations, off-the-shelf chains, and a declarative expression language (LCEL) to compose chains easily. You can use LangChain libraries in Python or JavaScript, set up your environment, and start building your applications with the provided guidance and templates.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can Langchain help build my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
