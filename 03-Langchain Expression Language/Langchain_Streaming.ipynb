{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Streaming\n",
    "\n",
    "深入研究 Langchain 流式输出 [Streaming With LangChain](https://python.langchain.com/docs/expression_language/streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up local llm on Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (0.1.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.20 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.22 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rionzhao/miniforge3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 Jupyter Notebook 中运行 Python上下文异步代码，需要安装nest_asyncio 包，该包提供对在嵌套事件循环中运行异步代码的支持。\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM model\n",
    "# See: https://python.langchain.com/docs/integrations/llms/ollama\n",
    "llm = Ollama(model=\"mistral:latest\")\n",
    "\n",
    "# prompt与输出\n",
    "template = \"\"\"Answer the Question: {question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 处理流水线\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'd be happy to introduce you to Beijing, the magnificent capital city of China. Located in the northern part of the country, Beijing is a bustling metropolis with over 21 million residents. It is renowned for its rich history, vibrant culture, and significant role as a political, educational, and cultural center of China.\\n\\nBeijing is home to many of China's most famous landmarks, including the Forbidden City, which was once the imperial palace and now serves as a UNESCO World Heritage Site; the Temple of Heaven, an ancient religious site and architectural masterpiece; and the Great Wall of China, one of the Seven Wonders of the Medieval World.\\n\\nThe city is also famous for its delicious cuisine, such as Peking Roast Duck and Jiaozi (dumplings). Beijing's streets come alive with an intoxicating mix of old and new, traditional and modern. Modern high-rises stand proudly alongside ancient temples and hutongs (traditional alleyways).\\n\\nBeijing is a global city and is home to many international businesses and embassies. It also hosts numerous world-class universities, attracting students from around the world. The city boasts a dynamic nightlife scene, with an array of bars, restaurants, and entertainment venues.\\n\\nBeijing's climate is continental and can be quite cold in winter, while summers can be hot and humid. Despite its size and hustle and bustle, Beijing retains a unique charm that attracts millions of visitors each year. Whether you are a history buff, a foodie, or simply an adventurous traveler, Beijing has something to offer for everyone.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"介绍一下北京\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流式输出的 2 个方法\n",
    "\n",
    "1. astream(): 默认的流式输出方法\n",
    "2. async astream_events and async astream_log：它们提供了一种从链中传输中间步骤和最终输出的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. astream 方法\n",
    "\n",
    "需要搭配 async 和 for 循环使用，流式输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I|'|m| an| artificial| intelligence| designed| to| assist| with| information| and| answer| questions| to| the| best| of| my| ability|.| I| don|'|t| have| a| physical| self| or| personal| experiences|,| so| I| can|'|t| tell| you| about| myself| in| that| way|.| However|,| I| can| provide| you| with| accurate| information| on| a| wide| range| of| topics|,| solve| complex| problems|,| and| even| generate| creative| content|.| Let| me| know| how| I| can| help| you| today|!||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in chain.astream({\"question\": \"hello. tell me something about yourself\"}):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看不同的 chunk 的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm an artificial intelligence designed to assist with information and answer questions to the best of my ability\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str = \"\"\n",
    "for i in range(20):\n",
    "    str += chunks[i]\n",
    "str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON 数据的流式输出\n",
    "\n",
    "对于 Function Calling 的场景，需要 llm 返回 json 结构的数据。以下是对 json 输出数据做流式输出的范例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'Fr'}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 6}]}\n",
      "{'countries': [{'name': 'France', 'population': 67}]}\n",
      "{'countries': [{'name': 'France', 'population': 670}]}\n",
      "{'countries': [{'name': 'France', 'population': 6702}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022}]}\n",
      "{'countries': [{'name': 'France', 'population': 670220}]}\n",
      "{'countries': [{'name': 'France', 'population': 6702200}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Sp'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 4}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 467}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 4675}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 467548}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 4675480}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'J'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 1}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 12}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 126}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 1265}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 12651}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 126510}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 1265100}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 12651000}]}\n",
      "{'countries': [{'name': 'France', 'population': 67022000}, {'name': 'Spain', 'population': 46754800}, {'name': 'Japan', 'population': 126510000}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "async for text in chain.astream({\"question\": 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们继续模拟 Function Calling 的场景，假设程序返回了一个JSON数据，我们需要设计函数提取出其中的关键信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "# 非流式输出的处理函数\n",
    "# 直接输出结果\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"A function that does not operates on input streams and breaks streaming.\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "    \n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "    \n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "    \n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser() | _extract_country_names\n",
    "\n",
    "async for text in chain.astream({\"question\": 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fr|France|Sp|Spain|J|Japan|"
     ]
    }
   ],
   "source": [
    "# 流式输出函数，使用yield处理\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"A function that operates on input streams.\"\"\"\n",
    "    country_names_so_far = set()\n",
    "\n",
    "    async for input in input_stream:\n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                yield name\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "chain =  llm | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream('output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-streaming components\n",
    "\n",
    "在不支持 stream 输出的组件中（比如Retrievers），使用 stream 会直接输出最后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "311.51s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/21/d1/f44f02d87d238cd51174f19c55e8a0a3cd1a6207e4eb526c847939986556/faiss_cpu-1.7.4-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.3 kB)\n",
      "Downloading faiss_cpu-1.7.4-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0042d8350a8742e69f499ab6de366f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a497fd97ca70403e85eb6b328d1d569f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea9d24fb6fb41d1a0f72247a466443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febc549b2d79462d8df484df64af67ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9818c87796745e698fb60cc44393b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372876fd1ec0416cafb4fc6a0e3a2a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7de9cb94ec4ad487fd6360ab1f8abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef04357bc617465a9eaf44bd9e8e3dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding Model\n",
    "modelPath = \"BAAI/bge-base-en-v1.5\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "# model_kwargs = {'device':'cpu'}\n",
    "model_kwargs = {'device':'mps'} # mps是苹果专用的\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='harrison worked at kensho'),\n",
       "  Document(page_content='harrison likes spicy food')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\", \"harrison likes spicy food\"],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chunks = [chunk for chunk in retriever.stream(\"where did harrison work?\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 流水线中使用 “不支持异步组件” 仍可以实现异步输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based| on| the| given| context|,| Harrison| worked| at| K|ens|ho|.| Here| are| three| made|-|up| sentences| about| K|ens|ho|:|\n",
      "|\n",
      "|1|.| K|ens|ho| is| a| pione|ering| tech| company| known| for| its| innovative| solutions| in| the| financial| sector|,| where| Harrison| contributed| significantly| as| an| este|emed| team| member|.|\n",
      "|2|.| The| office| environment| at| K|ens|ho| is| vibr|ant| and| dynamic|,| filled| with| intellectual| discussions| over| cups| of| coffee|,| fuel|ing| creativity| and| collaboration| among| employees| like| Harrison|.|\n",
      "|3|.| Despite| being| a| cutting|-|edge| tech| company|,| K|ens|ho| maint|ains| a| unique| culture| that| values| cam|ar|ader|ie| and| fun| –| one| day|,| Harrison| even| brought| in| his| favorite| sp|icy| cu|isine| to| share| with| his| team|.||"
     ]
    }
   ],
   "source": [
    "for chunk in retrieval_chain.stream(\n",
    "    \"Where did harrison work?\" \"Write 3 made up sentences about this place.\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
