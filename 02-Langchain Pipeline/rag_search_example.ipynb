{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Search Example\n",
    "\n",
    "通过 langchain 实现一个简单的 RAG 系统\n",
    "\n",
    "先准备 LLM 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# LLM model\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    openai_api_key=\"not-needed\"\n",
    ")\n",
    "\n",
    "# Embedding Model\n",
    "modelPath = \"BAAI/bge-base-en-v1.5\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "# model_kwargs = {'device':'cpu'}\n",
    "model_kwargs = {'device':'cuda'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")\n",
    "\n",
    "\n",
    "# load the data from web\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/get_started/introduction\")\n",
    "docs = loader.load()\n",
    "\n",
    "# vetorize and store\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 langchain 处理流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "chain = setup_and_retrieval | prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索资料，并交由LLM处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain 是一个框架，用于开发由语言模型驱动的应用程序。它有以下特点和优势：\\n\\n1. **应用程序功能**：LangChain 允许应用程序具备上下文感知能力，通过连接语言模型到各种源（如提示说明、示例或内容来支持响应）进行推理。\\n\\n2. **组件与集成**：框架包含 LangChain 库，提供了可组合的工具和集成，用于语言模型的工作。这些组件是模块化的，易于使用，并且可以独立于整个 LangChain 框架使用。此外，还包含预构建的链和代理，简化了高级任务的实现。\\n\\n3. **快速入门**：有 Quickstart 指南帮助用户熟悉框架，通过模板快速构建第一个 LangChain 应用程序。\\n\\n4. **生产友好**：LangSmith 提供了调试、测试、评估和监控功能，确保在生产环境中可以持续改进和自信地部署应用。\\n\\n5. **易用性与定制**：LCEL 是一个声明式的链编排方式，设计用于支持将原型直接部署到生产中，无需更改代码。它提供了标准接口和模块，如模型I/O、检索和代理工具。\\n\\n6. **生态系统**：LangChain 链接了一个丰富的生态系统，与其他工具无缝集成，并且易于扩展。\\n\\n7. **安全**：文档建议遵循最佳实践来确保开发过程的安全。\\n\\n8. **跨语言支持**：除了Python库外，还有JavaScript LangChain库供选择。\\n\\n总之，LangChain 提供了一整套工具和平台，简化了构建基于语言模型的应用程序的过程，并提供了强大的功能和灵活性。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"langchain 有什么特点与优势?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The LangChain packages provide components and integrations for working with language models in a modular and easy-to-use way, supporting both simple chains like \"prompt + LLM\" and complex cognitive architectures. This allows developers to build applications that are context-aware and can reason based on provided context. Additionally, LangChain offers off-the-shelf chains and agents for various tasks, making it easy to get started and customize existing chains. The framework also includes a developer platform (LangSmith) for debugging, testing, evaluation, and monitoring chains, and a range of resources for common end-to-end use cases and integrations with other tools in the ecosystem. Overall, LangChain simplifies the application lifecycle by providing a comprehensive set of tools for building applications powered by language models.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is the benefit of using langchain?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
